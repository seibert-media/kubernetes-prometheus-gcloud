# Alert for any instance that is unreachable for >5 seconds.
ALERT InstanceDown
	IF up == 0
	FOR 5s
	LABELS { severity = "info" }
	ANNOTATIONS {
	summary = "Instance {{ $labels.instance }} down",
	description = "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 seconds.",
	}

# Alert disk space below 20% free
ALERT DiskOutOfSpace
	IF (max(diskstatus_bytesfree / diskstatus_bytestotal) by (app)) < 0.2
	FOR 1m
	LABELS {
		severity = "warning",
	}
	ANNOTATIONS {
		summary = "Disk of {{ $labels.app }} space",
		description = "{{ $labels.app }} is below 20% free space for more than 1 minutes.",
	}

# Alert disk space below 10% free
ALERT DiskOutOfSpace
	IF (max(diskstatus_bytesfree / diskstatus_bytestotal) by (app)) < 0.1
	FOR 1m
	LABELS {
		severity = "critical",
	}
	ANNOTATIONS {
		summary = "Disk of {{ $labels.app }} space",
		description = "{{ $labels.app }} is below 10% free space for more than 1 minutes.",
	}

# Alert disk space below 20% free
ALERT DiskOutOfInodes
	IF (max(diskstatus_inodesfree / diskstatus_inodestotal) by (app)) < 0.2
	FOR 1m
	LABELS {
		severity = "warning",
	}
	ANNOTATIONS {
		summary = "Disk of {{ $labels.app }} inodes",
		description = "{{ $labels.app }} is below 20% free inodes for more than 1 minutes.",
	}

# Alert disk space below 10% free
ALERT DiskOutOfInodes
	IF (max(diskstatus_inodesfree / diskstatus_inodestotal) by (app)) < 0.1
	FOR 1m
	LABELS {
		severity = "critical",
	}
	ANNOTATIONS {
		summary = "Disk of {{ $labels.app }} inodes",
		description = "{{ $labels.app }} is below 10% free inodes for more than 1 minutes.",
	}

# Alert Backup is missing for more than 2 days
ALERT BackupMissing
	IF (time() - max(max_over_time(backup_verliernix_last_rsync_backup[1d])) by (app)) / (60 * 60) > (24 * 2)
	FOR 1h
	LABELS {
		severity = "warning",
	}
	ANNOTATIONS {
		summary = "Backup of {{ $labels.app }} missing",
		description = "{{ $labels.app }} has no verliernix backup for more than 2 days",
	}

# Alert Backup is missing for more than 3 days
ALERT BackupMissing
	IF (time() - max(max_over_time(backup_verliernix_last_rsync_backup[1d])) by (app)) / (60 * 60) > (24 * 3)
	FOR 1h
	LABELS {
		severity = "critical",
	}
	ANNOTATIONS {
		summary = "Backup of {{ $labels.app }} missing",
		description = "{{ $labels.app }} has no verliernix backup for more than 3 days",
	}

# Alert NFS Backup is missing for more than 2 days
ALERT BackupNfsMissing
	IF (time() - max(max_over_time(backup_verliernix_last_rsync_backup{app="nfs-metrics-verliernix"}[1d])) by (app)) / (60 * 60) > (24 * 2)
	FOR 1h
	LABELS {
		severity = "warning",
	}
	ANNOTATIONS {
		summary = "Backup of {{ $labels.app }} missing",
		description = "{{ $labels.app }} has no verliernix backup for more than 2 days",
	}

# Alert NFS Backup is missing for more than 3 days
ALERT BackupNfsMissing
	IF (time() - max(max_over_time(backup_verliernix_last_rsync_backup{app="nfs-metrics-verliernix"}[1d])) by (app)) / (60 * 60) > (24 * 3)
	FOR 1h
	LABELS {
		severity = "critical",
	}
	ANNOTATIONS {
		summary = "Backup of {{ $labels.app }} missing",
		description = "{{ $labels.app }} has no verliernix backup for more than 3 days",
	}

# Alert No available Backup data
ALERT BackupNfsMissing
	IF absent(backup_verliernix_last_rsync_backup{app="nfs-metrics-verliernix"})
	FOR 1h
	LABELS {
		severity = "critical",
	}
	ANNOTATIONS {
		summary = "Backup of {{ $labels.app }} missing",
		description = "{{ $labels.app }} has no available verliernix backup data",
	}

# Alert for any failed HTTP/s Status Codes that that arise for >5 minutes.
ALERT HttpError
	IF probe_success == 0
	FOR 5m
	LABELS { severity = "critical" }
	ANNOTATIONS {
		summary = "Instance {{ $labels.instance }} down",
		description = "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.",
	}

# Alert for any failed HTTP/s Status Codes that that arise for >5 seconds.
ALERT HttpError
	IF probe_success == 0
	FOR 5s
	LABELS { severity = "info" }
	ANNOTATIONS {
		summary = "Instance {{ $labels.instance }} down",
		description = "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 seconds.",
	}

# Alert if >1 Jenkins Job is stuck for more than 2h.
ALERT JenkinsJobStuck
	IF min_over_time(jenkins_stuckBuilds[2h]) > 1
	FOR 5s
	LABELS { severity = "critical" }
	ANNOTATIONS {
		summary = "Jenkins has stuck builds",
		description = "A job has been stuck for more than 10 minutes.",
	}

# Alert if >1 Jenkins Job is stuck for more than 2h.
ALERT JenkinsQueueStuck
	IF min_over_time(jenkins_queueLength[2h]) > 5
	FOR 5s
	LABELS { severity = "critical" }
	ANNOTATIONS {
		summary = "Jenkins Queue Full",
		description = "Jenkins Queue has been full for more than 10 minutes.",
	}

# Alert if a Jenkins master branch is red for more than 5min.
ALERT JenkinsMasterRed
	IF max by(name)(jenkins_job_color{branch="master", name!~"Example.*"}) > 0
	FOR 6h
	LABELS { severity = "critical" }
	ANNOTATIONS {
		summary = "Jenkins Master Red",
		description = "The master of Jenkins Job {{ $labels.name }} has been red for more than 5min.",
	}
